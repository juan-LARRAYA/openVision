#!/usr/bin/env python3
"""
Demo script para probar los 3 modelos de visiÃ³n artificial mÃ¡s populares de Hugging Face
"""

import requests
import json
import time
from pathlib import Path

def test_api_endpoint(endpoint, description):
    """Prueba un endpoint de la API"""
    print(f"\nğŸ” Probando {description}...")
    try:
        response = requests.get(f"http://localhost:8000/{endpoint}", timeout=5)
        if response.status_code == 200:
            print(f"âœ… {description} - API disponible")
            return True
        else:
            print(f"âŒ {description} - Error {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"âŒ {description} - Error de conexiÃ³n: {e}")
        return False

def main():
    print("ğŸ¤– Demo de los 3 Modelos de VisiÃ³n Artificial MÃ¡s Populares de Hugging Face")
    print("=" * 80)
    
    # Verificar que la API estÃ© funcionando
    print("\nğŸ“¡ Verificando conexiÃ³n con la API...")
    if not test_api_endpoint("", "API principal"):
        print("\nâŒ La API no estÃ¡ disponible. AsegÃºrate de que el servidor estÃ© ejecutÃ¡ndose:")
        print("   uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000")
        return
    
    # Obtener informaciÃ³n de los modelos
    try:
        response = requests.get("http://localhost:8000/")
        data = response.json()
        print(f"\nğŸ“‹ Modelos disponibles:")
        for i, model in enumerate(data["models"], 1):
            print(f"   {i}. {model}")
    except Exception as e:
        print(f"âŒ Error obteniendo informaciÃ³n de modelos: {e}")
        return
    
    print("\n" + "=" * 80)
    print("ğŸ¯ CAPACIDADES DE CADA MODELO")
    print("=" * 80)
    
    print("\n1ï¸âƒ£  CLIP (openai/clip-vit-base-patch32)")
    print("   ğŸ¯ QuÃ© hace: ClasificaciÃ³n zero-shot usando texto y imÃ¡genes")
    print("   ğŸ’¡ Capacidades:")
    print("      â€¢ Puede clasificar imÃ¡genes usando descripciones en lenguaje natural")
    print("      â€¢ No necesita entrenamiento previo para nuevas categorÃ­as")
    print("      â€¢ Entiende la relaciÃ³n entre texto e imÃ¡genes")
    print("   ğŸ“ Ejemplo de uso:")
    print("      â€¢ Input: Imagen + ['una persona', 'un animal', 'un objeto']")
    print("      â€¢ Output: Probabilidades para cada categorÃ­a")
    
    print("\n2ï¸âƒ£  ViT (google/vit-base-patch16-224)")
    print("   ğŸ” QuÃ© hace: ClasificaciÃ³n de imÃ¡genes usando Vision Transformer")
    print("   ğŸ’¡ Capacidades:")
    print("      â€¢ Clasifica imÃ¡genes en 1000 categorÃ­as de ImageNet")
    print("      â€¢ Muy preciso para objetos comunes")
    print("      â€¢ Basado en arquitectura Transformer")
    print("   ğŸ“ Ejemplo de uso:")
    print("      â€¢ Input: Imagen")
    print("      â€¢ Output: ['Golden Retriever 85%', 'Labrador 12%', 'Beagle 3%']")
    
    print("\n3ï¸âƒ£  DETR (facebook/detr-resnet-50)")
    print("   ğŸ“¦ QuÃ© hace: DetecciÃ³n de objetos usando Detection Transformer")
    print("   ğŸ’¡ Capacidades:")
    print("      â€¢ Detecta y localiza mÃºltiples objetos en una imagen")
    print("      â€¢ Dibuja cajas delimitadoras alrededor de objetos")
    print("      â€¢ Puede detectar mÃºltiples instancias del mismo objeto")
    print("   ğŸ“ Ejemplo de uso:")
    print("      â€¢ Input: Imagen")
    print("      â€¢ Output: [{'label': 'person', 'box': [x,y,w,h], 'score': 0.95}]")
    
    print("\n" + "=" * 80)
    print("ğŸš€ CÃ“MO USAR LA APLICACIÃ“N")
    print("=" * 80)
    
    print("\n1. ğŸ“± Abre el frontend en tu navegador:")
    print("   file:///path/to/frontend/index.html")
    
    print("\n2. ğŸ“· Permite acceso a la cÃ¡mara cuando se solicite")
    
    print("\n3. ğŸ® Prueba cada modelo:")
    print("   â€¢ ğŸ” ViT Classifier: Clasifica lo que ve la cÃ¡mara")
    print("   â€¢ ğŸ¯ CLIP Zero-Shot: Clasifica usando categorÃ­as predefinidas")
    print("   â€¢ ğŸ“¦ DETR Object Detection: Detecta y marca objetos con cajas")
    print("   â€¢ ğŸ¨ CLIP Custom: Usa tus propios prompts de texto")
    
    print("\n4. ğŸ¨ Para CLIP Custom, prueba prompts como:")
    print("   â€¢ 'una persona feliz, una persona triste, una persona neutral'")
    print("   â€¢ 'un gato, un perro, un pÃ¡jaro'")
    print("   â€¢ 'comida, bebida, tecnologÃ­a'")
    
    print("\n" + "=" * 80)
    print("ğŸ’¡ CASOS DE USO PRÃCTICOS")
    print("=" * 80)
    
    print("\nğŸ¥ CLIP - AnÃ¡lisis mÃ©dico:")
    print("   Prompts: 'radiografÃ­a normal, fractura, inflamaciÃ³n'")
    
    print("\nğŸ›’ ViT - E-commerce:")
    print("   Clasificar productos automÃ¡ticamente por categorÃ­a")
    
    print("\nğŸš— DETR - VehÃ­culos autÃ³nomos:")
    print("   Detectar peatones, carros, seÃ±ales de trÃ¡fico")
    
    print("\nğŸ­ DETR - Control de calidad:")
    print("   Detectar defectos en productos manufacturados")
    
    print("\nğŸ“± CLIP - Redes sociales:")
    print("   Moderar contenido: 'contenido apropiado, contenido inapropiado'")
    
    print("\n" + "=" * 80)
    print("âœ¨ Â¡La aplicaciÃ³n estÃ¡ lista para usar!")
    print("   Abre el frontend y experimenta con tu cÃ¡mara")
    print("=" * 80)

if __name__ == "__main__":
    main()
