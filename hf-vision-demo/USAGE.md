# HF Vision Demo - Gu√≠a de Uso

## Descripci√≥n General

HF Vision Demo es una aplicaci√≥n web de visi√≥n artificial que ejecuta modelos de IA directamente en tu navegador usando Hugging Face Transformers.js con aceleraci√≥n WebGPU.

**Caracter√≠sticas principales:**
- ‚úÖ Ejecuta modelos de IA 100% en el navegador (sin servidor)
- ‚úÖ **Funciona completamente offline** (despu√©s de la primera descarga de modelos)
- ‚úÖ Aceleraci√≥n por hardware con WebGPU
- ‚úÖ Fallback autom√°tico a WASM/CPU si WebGPU no est√° disponible
- ‚úÖ Interfaz minimalista y moderna
- ‚úÖ Gesti√≥n din√°mica de modelos desde la UI
- ‚úÖ Sin dependencias de CDN externos (fuentes del sistema)

---

## üöÄ C√≥mo Ejecutar la Aplicaci√≥n

### Requisitos Previos

- **Navegador recomendado**: Chrome 113+ o Edge 113+ (para WebGPU)
- **C√°mara web**: Necesaria para capturar im√°genes
- **Conexi√≥n a internet**: Para descargar modelos la primera vez

### Opci√≥n 1: npm run dev (Recomendado - M√ÅS F√ÅCIL)

Si tienes Node.js instalado:

```bash
# Navega a la carpeta del proyecto
cd "hf-vision-demo"

# Instalar dependencias (solo la primera vez)
npm install

# Ejecutar servidor de desarrollo
npm run dev
```

Esto autom√°ticamente:
- ‚úÖ Inicia el servidor en `http://localhost:8080`
- ‚úÖ Abre tu navegador autom√°ticamente
- ‚úÖ Todo en un solo comando

### Opci√≥n 2: Servidor HTTP con Python

Alternativa usando el servidor HTTP integrado de Python:

```bash
# Navega a la carpeta del proyecto
cd "hf-vision-demo"

# Python 3
python3 -m http.server 8080

# O si tienes Python 2
python -m SimpleHTTPServer 8080
```

Luego abre tu navegador en:
```
http://localhost:8080
```

### Opci√≥n 3: Live Server (VS Code)

Si usas Visual Studio Code:

1. Instala la extensi√≥n "Live Server"
2. Abre la carpeta `hf-vision-demo` en VS Code
3. Haz clic derecho en `index.html`
4. Selecciona "Open with Live Server"

Se abrir√° autom√°ticamente en tu navegador.

### Opci√≥n 4: Desplegar en Vercel (Producci√≥n)

Para desplegar online gratuitamente:

```bash
# Instalar Vercel CLI (solo una vez)
npm install -g vercel

# Navega a la carpeta del proyecto
cd "hf-vision-demo"

# Desplegar
vercel
```

Sigue las instrucciones en pantalla. Vercel te dar√° una URL p√∫blica.

### ‚ö†Ô∏è Importante: HTTPS Requerido

**La c√°mara web solo funciona con HTTPS o localhost.**

- ‚úÖ `http://localhost:8080` - Funciona
- ‚úÖ `https://tu-sitio.com` - Funciona
- ‚ùå `http://192.168.1.5:8080` - NO funciona (no es localhost)

Si necesitas acceder desde otro dispositivo en tu red local, necesitar√°s configurar HTTPS.

### Primera Carga: Paciencia

La **primera vez** que cargas la aplicaci√≥n:
- Descarga ~430 MB de modelos desde Hugging Face
- Puede tomar **2-5 minutos** dependiendo de tu conexi√≥n
- Ver√°s barras de progreso para cada modelo

**Cargas posteriores** son mucho m√°s r√°pidas (~10-20 segundos) porque los modelos est√°n cacheados en el navegador.

### Verificar que Funciona

1. Deber√≠as ver un modal indicando el estado de WebGPU
2. Ver√°s un video en vivo de tu c√°mara
3. Tres botones aparecer√°n: "ViT Classifier", "CLIP Zero-Shot", "DETR Object Detection"
4. Abre la consola del navegador (F12) para ver logs detallados

### üîå Modo Offline

**Despu√©s de la primera carga**, la aplicaci√≥n funciona completamente sin internet:

1. **Primera vez** (CON internet):
   - Descarga ~430 MB de modelos desde Hugging Face CDN
   - Los modelos se cachean en el navegador (IndexedDB)
   - Toma 2-5 minutos

2. **Usos posteriores** (SIN internet):
   - Los modelos ya est√°n cacheados localmente
   - La app inicia en ~10-20 segundos
   - Todo funciona offline (excepto agregar nuevos modelos)
   - Las fuentes son del sistema (no requieren Google Fonts)

**Para limpiar el cache y liberar espacio:**
```javascript
// En la consola del navegador (F12)
window.appDebug.clearModelCache();
```

---

## Arquitectura

### Client-Side AI

La aplicaci√≥n es completamente client-side:
- **Sin servidor backend**: Toda la inferencia ocurre en tu navegador
- **Privacidad total**: Las im√°genes nunca salen de tu dispositivo
- **WebGPU**: Aceleraci√≥n por hardware usando tu GPU
- **Fallback WASM**: Si WebGPU no est√° disponible, usa CPU

### Modelos Incluidos

Por defecto, la aplicaci√≥n incluye 3 modelos de visi√≥n artificial:

| Modelo | Tarea | Descripci√≥n |
|--------|-------|-------------|
| **ViT** (Vision Transformer) | Image Classification | Clasifica im√°genes en 1000 categor√≠as |
| **CLIP** | Zero-Shot Classification | Clasifica con prompts personalizados |
| **DETR** | Object Detection | Detecta y localiza objetos con bounding boxes |

Todos los modelos usan versiones optimizadas de Hugging Face (`Xenova/*`).

---

## Verificar si WebGPU est√° Activo

### 1. Modal al Cargar

Cuando abres la aplicaci√≥n, ver√°s un modal que indica:

- **‚úì WebGPU Activo**: Tu navegador soporta WebGPU, aceleraci√≥n habilitada
- **‚ö† WebGPU No Disponible**: Ejecutando en modo CPU (m√°s lento)

El modal muestra:
- Estado actual (activo o no disponible)
- Raz√≥n si no est√° disponible
- Recomendaci√≥n de navegadores compatibles

### 2. Badge en el Header

En el header principal, ver√°s un badge que indica el backend:

- **WebGPU** (azul) = Aceleraci√≥n GPU activa
- **CPU (WASM)** (√°mbar) = Modo fallback CPU

### 3. Resultados de Inferencia

Cada resultado muestra el backend usado:

- **WebGPU ¬∑ 0.5s** = Inferencia con GPU (r√°pido)
- **WASM ¬∑ 2.3s** = Inferencia con CPU (m√°s lento)

El badge est√° consolidado: muestra backend y tiempo en un solo elemento.

### 4. Consola del Navegador (F12)

Abre DevTools (F12) y busca logs como:

```
Iniciando HF Vision Demo...
Detectando WebGPU...
‚úì WebGPU disponible
  - FP16 support: true
  - Max buffer size: 268435456
‚îå‚îÄ Cargando modelo: vit
‚îú‚îÄ Backend: WEBGPU
‚îú‚îÄ Dtype: fp32
‚îî‚îÄ Ruta: Xenova/vit-base-patch16-224
‚úì Modelo vit cargado exitosamente con WEBGPU
‚ñ∂ Ejecutando vit con WebGPU...
‚úì vit completado en 0.52s
```

---

## C√≥mo Cambiar de Modelos

### Opci√≥n 1: Panel de Configuraci√≥n (Recomendado)

1. Haz clic en el icono de engranaje (‚öô) en la esquina superior derecha
2. Se abrir√° el panel de configuraci√≥n de modelos
3. Ver√°s la lista de modelos disponibles con su estado:
   - **Verde "Activo"**: Modelo actualmente en uso
   - **Azul "Cargado"**: Modelo disponible para usar
   - **Gris "No cargado"**: Modelo no disponible

El panel muestra para cada modelo:
- Nombre completo
- Descripci√≥n (ruta de Hugging Face)
- Tipo de tarea
- Estado de carga

### Opci√≥n 2: Agregar Nuevos Modelos desde la UI

1. Abre el panel de configuraci√≥n (‚öô)
2. Despl√°zate a la secci√≥n "Agregar Nuevo Modelo"
3. Completa el formulario:
   - **ID del modelo**: Identificador √∫nico (ej: `resnet`, `mobilenet`)
   - **Nombre**: Nombre legible (ej: `ResNet-50`, `MobileNet V2`)
   - **Ruta HuggingFace**: Modelo en el Hub (ej: `Xenova/resnet-50`)
   - **Tipo de tarea**: Selecciona el tipo apropiado
     - Image Classification
     - Zero-Shot Classification
     - Object Detection
4. Haz clic en "Agregar Modelo"
5. El modelo se guardar√° en localStorage
6. **Recarga la p√°gina** para que est√© disponible

**Nota**: Los modelos personalizados persisten entre sesiones gracias a localStorage.

### Opci√≥n 3: Editar config.js (Avanzado)

Si necesitas personalizaci√≥n profunda:

1. Abre [js/config.js](js/config.js)
2. Agrega una entrada a `MODEL_REGISTRY`:

```javascript
miModelo: {
  id: 'miModelo',
  name: 'Mi Modelo Custom',
  icon: '',
  task: 'image-classification',
  model: 'Xenova/mi-modelo-hf',
  displayName: 'Mi Modelo Custom',
  description: 'Descripci√≥n del modelo',
  buttonClass: 'miModelo-btn',
  resultId: 'miModeloResult',
  webgpu: {
    device: 'webgpu',
    dtype: 'fp32'  // Alta precisi√≥n
  },
  fallback: {
    device: 'wasm',
    dtype: 'q8'    // Cuantizado para CPU
  }
}
```

3. Guarda el archivo
4. Recarga la aplicaci√≥n

**Configuraci√≥n de Device y Dtype**:
- **webgpu + fp32**: M√°ximo rendimiento, alta precisi√≥n
- **wasm + q8**: Fallback CPU, modelo cuantizado (m√°s r√°pido, menos preciso)
- **wasm + fp32**: CPU con precisi√≥n completa (muy lento)

---

## Navegadores Soportados

### WebGPU Completo ‚ö°

| Navegador | Versi√≥n M√≠nima | Notas |
|-----------|----------------|-------|
| Google Chrome | 113+ | Soporte completo, recomendado |
| Microsoft Edge | 113+ | Soporte completo |

### Fallback WASM üîß

| Navegador | Notas |
|-----------|-------|
| Firefox | WebGPU experimental (requiere flag) |
| Safari | WebGPU no disponible, usar√° CPU |
| Navegadores antiguos | Funcionar√° en modo CPU |

**Recomendaci√≥n**: Para mejor rendimiento, usa Chrome 113+ o Edge 113+.

### Verificar WebGPU en Chrome

1. Abre `chrome://gpu`
2. Busca "WebGPU" en la p√°gina
3. Debe decir "WebGPU: Hardware accelerated"

Si aparece "Disabled":
1. Ve a `chrome://flags`
2. Busca "WebGPU"
3. Habilita "Unsafe WebGPU" (solo para pruebas)

---

## Performance Esperada

### Con WebGPU (GPU)

| Modelo | Tiempo Aprox. | Notas |
|--------|---------------|-------|
| ViT | ~0.3-0.6s | Clasificaci√≥n r√°pida |
| CLIP | ~0.5-1.0s | Depende del n√∫mero de prompts |
| DETR | ~0.8-1.5s | Detecci√≥n de objetos m√°s compleja |

### Con WASM (CPU)

| Modelo | Tiempo Aprox. | Notas |
|--------|---------------|-------|
| ViT | ~2-5s | Depende del procesador |
| CLIP | ~4-8s | M√°s lento con muchos prompts |
| DETR | ~8-15s | Requiere m√°s procesamiento |

*Tiempos aproximados, var√≠an seg√∫n hardware*

**WebGPU puede ser hasta 10x m√°s r√°pido que WASM.**

---

## C√≥mo Funciona la Aplicaci√≥n

### Flujo Completo

```
‚îå‚îÄ Usuario carga la p√°gina
‚îÇ
‚îú‚îÄ 1. Detectar WebGPU
‚îÇ  ‚îî‚îÄ Si disponible ‚Üí usar GPU
‚îÇ  ‚îî‚îÄ Si no ‚Üí usar CPU (WASM)
‚îÇ
‚îú‚îÄ 2. Mostrar modal de estado WebGPU
‚îÇ  ‚îî‚îÄ Usuario cierra modal
‚îÇ
‚îú‚îÄ 3. Cargar Transformers.js desde CDN
‚îÇ  ‚îî‚îÄ Versi√≥n: 2.17.2
‚îÇ
‚îú‚îÄ 4. Iniciar c√°mara web
‚îÇ  ‚îî‚îÄ Solicitar permiso de c√°mara
‚îÇ
‚îú‚îÄ 5. Cargar modelos de IA (secuencial)
‚îÇ  ‚îú‚îÄ ViT (30-60s primera vez)
‚îÇ  ‚îú‚îÄ CLIP (30-60s primera vez)
‚îÇ  ‚îî‚îÄ DETR (30-60s primera vez)
‚îÇ  ‚îî‚îÄ Los modelos se cachean en el navegador
‚îÇ
‚îú‚îÄ 6. Mostrar controles y botones
‚îÇ
‚îî‚îÄ 7. Usuario listo para usar
   ‚îú‚îÄ Hacer clic en bot√≥n de modelo
   ‚îú‚îÄ Capturar imagen de c√°mara
   ‚îú‚îÄ Ejecutar inferencia
   ‚îî‚îÄ Mostrar resultados
```

### Primera Carga vs. Cargas Posteriores

**Primera carga** (~2-3 minutos):
- Descarga modelos desde Hugging Face CDN
- Los modelos se cachean en el navegador

**Cargas posteriores** (~10-20 segundos):
- Modelos se cargan del cache del navegador
- Mucho m√°s r√°pido

---

## Usar la Aplicaci√≥n

### 1. Clasificaci√≥n con ViT

1. Col√≥cate frente a la c√°mara con el objeto a clasificar
2. Haz clic en **"ViT Classifier"**
3. La aplicaci√≥n captura la imagen y ejecuta el modelo
4. Ver√°s las 5 predicciones principales con % de confianza

**Ejemplo de resultado**:
```
person: 95%
human face: 87%
portrait: 78%
...
```

### 2. Clasificaci√≥n Zero-Shot con CLIP

**Opci√≥n A: Prompts por defecto**
1. Haz clic en **"CLIP Zero-Shot"**
2. CLIP clasifica contra 9 categor√≠as predefinidas

**Opci√≥n B: Prompts personalizados**
1. Escribe tus prompts en el input (separados por comas)
   - Ejemplo: `cat, dog, bird, fish`
2. Haz clic en **"CLIP Custom"**
3. CLIP clasifica contra tus prompts personalizados

**Ejemplo de resultado**:
```
a photo of a person: 92%
a photo of an animal: 12%
a photo of food: 5%
...
```

### 3. Detecci√≥n de Objetos con DETR

1. Haz clic en **"DETR Object Detection"**
2. El modelo detecta y localiza objetos
3. Ver√°s:
   - Lista de objetos detectados con % de confianza
   - Bounding boxes dibujados en la imagen
   - Cada objeto con color diferente

**Ejemplo de resultado**:
```
person: 95% (bbox dibujado)
laptop: 87% (bbox dibujado)
cup: 78% (bbox dibujado)
...
```

---

## Troubleshooting

### WebGPU no se detecta en Chrome

**Soluci√≥n**:
1. Verifica que tengas Chrome 113+
2. Ve a `chrome://gpu` y busca "WebGPU"
3. Si aparece "Disabled":
   - Ve a `chrome://flags/#enable-unsafe-webgpu`
   - Habilita la opci√≥n
   - Reinicia Chrome

### Los modelos no cargan

**Posibles causas**:
- Conexi√≥n a internet lenta/intermitente
- Firewall bloqueando `cdn.jsdelivr.net`
- Navegador sin espacio en cache

**Soluciones**:
1. Verifica tu conexi√≥n a internet
2. Abre la consola (F12) y busca errores de red
3. Intenta limpiar el cache del navegador
4. Recarga la p√°gina

### La c√°mara no funciona

**Soluciones**:
1. Verifica permisos de c√°mara en configuraci√≥n del navegador
2. Aseg√∫rate de estar en HTTPS (o localhost)
3. Verifica que ninguna otra app est√© usando la c√°mara
4. Revisa la consola (F12) para errores

### La aplicaci√≥n est√° muy lenta

**Si est√°s en WASM (CPU)**:
- Esto es esperado, WASM es 5-10x m√°s lento que WebGPU
- Usa Chrome 113+ o Edge 113+ para WebGPU

**Si est√°s en WebGPU y sigue lento**:
- Verifica que tu GPU sea compatible
- Cierra otras apps que usen la GPU
- Reduce la resoluci√≥n de la c√°mara

### Error al agregar modelo personalizado

**Soluciones**:
1. Verifica que el ID del modelo sea √∫nico
2. Aseg√∫rate de que la ruta de Hugging Face sea correcta
   - Debe ser formato `Xenova/modelo-nombre`
3. Verifica que el tipo de tarea sea compatible
4. Revisa la consola para m√°s detalles

---

## Estructura de Archivos

```
hf-vision-demo/
‚îú‚îÄ‚îÄ index.html              # P√°gina principal
‚îú‚îÄ‚îÄ USAGE.md               # Esta gu√≠a
‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îî‚îÄ‚îÄ styles.css         # Estilos minimalistas oscuros
‚îî‚îÄ‚îÄ js/
    ‚îú‚îÄ‚îÄ main.js            # Orquestaci√≥n principal
    ‚îú‚îÄ‚îÄ models.js          # Carga de modelos y WebGPU
    ‚îú‚îÄ‚îÄ config.js          # Configuraci√≥n centralizada
    ‚îú‚îÄ‚îÄ camera.js          # Gesti√≥n de c√°mara
    ‚îî‚îÄ‚îÄ ui.js              # Gesti√≥n de interfaz
```

---

## Configuraci√≥n Avanzada

### Cambiar Versi√≥n de Transformers.js

Edita [js/config.js](js/config.js):

```javascript
export const APP_CONFIG = {
  transformersVersion: '2.17.2'  // Cambiar versi√≥n
  // ...
};
```

### Cambiar N√∫mero de Resultados

Edita [js/config.js](js/config.js):

```javascript
export const APP_CONFIG = {
  maxResults: 5  // Cambiar a 10, 15, etc.
  // ...
};
```

### Cambiar Resoluci√≥n de C√°mara

Edita [js/config.js](js/config.js):

```javascript
export const APP_CONFIG = {
  camera: {
    width: 640,   // Cambiar resoluci√≥n
    height: 480,
    facingMode: 'user'  // 'user' (frontal) o 'environment' (trasera)
  }
  // ...
};
```

### Deshabilitar WebGPU (forzar WASM)

Edita [js/config.js](js/config.js):

```javascript
export const WEBGPU_CONFIG = {
  enabled: false,  // Deshabilitar WebGPU
  // ...
};
```

---

## Debugging

La aplicaci√≥n expone un objeto `window.appDebug` para debugging:

```javascript
// En consola del navegador (F12)

// Ver estado de la aplicaci√≥n
appDebug.getState()

// Procesar imagen con un modelo espec√≠fico
appDebug.processImage('vit')

// Recargar todos los modelos
appDebug.reloadModels()
```

---

## FAQ

### ¬øLos modelos se descargan cada vez?

No. La primera vez se descargan desde Hugging Face CDN, pero se cachean en el navegador. Las cargas posteriores son mucho m√°s r√°pidas.

### ¬øPuedo usar la app sin c√°mara?

S√≠, pero necesitar√≠as modificar el c√≥digo para permitir subir im√°genes. Actualmente solo soporta c√°mara en vivo.

### ¬øCu√°nto espacio ocupan los modelos?

Aproximadamente:
- ViT: ~100 MB
- CLIP: ~150 MB
- DETR: ~180 MB

Total: ~430 MB en cache del navegador

### ¬øFunciona offline despu√©s de cargar?

Parcialmente. Los modelos est√°n cacheados, pero Transformers.js se carga desde CDN. Para uso 100% offline necesitar√≠as hospearlo localmente.

### ¬øPuedo usar modelos m√°s grandes?

S√≠, pero ten en cuenta:
- Modelos grandes tardan m√°s en descargar
- Pueden requerir m√°s RAM/VRAM
- El navegador puede quedarse sin memoria

Recomendaci√≥n: Usa modelos `Xenova/*` optimizados para navegador.

---

## Recursos

- [Transformers.js Docs](https://huggingface.co/docs/transformers.js)
- [WebGPU Spec](https://www.w3.org/TR/webgpu/)
- [Hugging Face Models](https://huggingface.co/models)
- [Xenova Models](https://huggingface.co/Xenova)

---

## Soporte

Si encuentras problemas:
1. Revisa esta gu√≠a
2. Abre la consola del navegador (F12) para ver errores
3. Verifica tu conexi√≥n a internet
4. Prueba con Chrome 113+ o Edge 113+

---

**¬°Disfruta experimentando con modelos de IA en tu navegador!** üöÄ
